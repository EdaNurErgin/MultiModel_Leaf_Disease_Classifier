{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2EpRYd2Lg2i",
        "outputId": "2f8064dc-07fe-4d2e-89d8-53ba78bb1a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow scikit-learn matplotlib seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38ZMJf2VNYNb",
        "outputId": "72c51aef-8d09-459c-e75a-6ed8aa01bfc4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Proje ana dizinin (sen kendine göre değiştirebilirsin)\n",
        "BASE_DIR = \"/content/drive/MyDrive/Colab Notebooks/Sugarcane Disease\""
      ],
      "metadata": {
        "id": "Jfy1SNSfNZne"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ham veri klasörü Sugarcane Disease'in kendisi\n",
        "RAW_DIR = BASE_DIR\n",
        "\n",
        "# Ayırılmış dataset buraya oluşturulacak\n",
        "SPLIT_DIR = os.path.join(BASE_DIR, \"dataset_split\")\n",
        "\n",
        "print(\"BASE_DIR   :\", BASE_DIR)\n",
        "print(\"RAW_DIR    :\", RAW_DIR)\n",
        "print(\"SPLIT_DIR  :\", SPLIT_DIR)\n",
        "\n",
        "print(\"RAW klasörü var mı?\", os.path.exists(RAW_DIR))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58iiLtjXOs3P",
        "outputId": "e11be7bf-bdb0-4371-c9d3-800e604bb065"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE_DIR   : /content/drive/MyDrive/Colab Notebooks/Sugarcane Disease\n",
            "RAW_DIR    : /content/drive/MyDrive/Colab Notebooks/Sugarcane Disease\n",
            "SPLIT_DIR  : /content/drive/MyDrive/Colab Notebooks/Sugarcane Disease/dataset_split\n",
            "RAW klasörü var mı? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = os.listdir(RAW_DIR)\n",
        "print(\"Bulunan sınıf klasörleri:\")\n",
        "for c in classes:\n",
        "    print(\"-\", c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFxIon1uOt84",
        "outputId": "5a480e7f-c516-4355-da29-861b9543fb7e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bulunan sınıf klasörleri:\n",
            "- Mosaic\n",
            "- RedRot\n",
            "- Healthy\n",
            "- Rust\n",
            "- Yellow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import random\n",
        "\n",
        "# Oranlar\n",
        "train_ratio = 0.7\n",
        "val_ratio   = 0.1\n",
        "test_ratio  = 0.2\n",
        "\n",
        "assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Oranlar 1 etmiyor!\"\n",
        "\n",
        "# Tekrarlanabilirlik için\n",
        "random.seed(42)\n",
        "\n",
        "# dataset_split altındaki ana klasörler\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    split_path = os.path.join(SPLIT_DIR, split)\n",
        "    os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "print(\"train/val/test klasörleri oluşturuldu/var.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R54i22q5O28g",
        "outputId": "70c2603e-08bb-462b-ccfe-f8f0f3af82e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/val/test klasörleri oluşturuldu/var.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Yalnızca resim uzantılarını dikkate alalım\n",
        "VALID_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp')\n",
        "\n",
        "for cls in classes:\n",
        "    class_path = os.path.join(RAW_DIR, cls)\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue  # klasör değilse geç\n",
        "\n",
        "    # Bu sınıfa ait tüm resimleri topla\n",
        "    images = [\n",
        "        f for f in os.listdir(class_path)\n",
        "        if f.lower().endswith(VALID_EXTENSIONS)\n",
        "    ]\n",
        "\n",
        "    if len(images) == 0:\n",
        "        print(f\"UYARI: '{cls}' klasöründe resim bulunamadı!\")\n",
        "        continue\n",
        "\n",
        "    random.shuffle(images)\n",
        "\n",
        "    n_total = len(images)\n",
        "    n_train = int(n_total * train_ratio)\n",
        "    n_val   = int(n_total * val_ratio)\n",
        "    n_test  = n_total - n_train - n_val  # kalan test\n",
        "\n",
        "    train_imgs = images[:n_train]\n",
        "    val_imgs   = images[n_train:n_train + n_val]\n",
        "    test_imgs  = images[n_train + n_val:]\n",
        "\n",
        "    print(f\"\\nSınıf: {cls}\")\n",
        "    print(f\"  Toplam: {n_total}\")\n",
        "    print(f\"  Train:  {len(train_imgs)}\")\n",
        "    print(f\"  Val:    {len(val_imgs)}\")\n",
        "    print(f\"  Test:   {len(test_imgs)}\")\n",
        "\n",
        "    # Her split için hedef klasör ve kopyalama\n",
        "    for split, split_imgs in zip([\"train\", \"val\", \"test\"],\n",
        "                                 [train_imgs, val_imgs, test_imgs]):\n",
        "        split_class_dir = os.path.join(SPLIT_DIR, split, cls)\n",
        "        os.makedirs(split_class_dir, exist_ok=True)\n",
        "\n",
        "        for img_name in split_imgs:\n",
        "            src = os.path.join(class_path, img_name)\n",
        "            dst = os.path.join(split_class_dir, img_name)\n",
        "            shutil.copy2(src, dst)\n",
        "\n",
        "print(\"\\n✅ Veri başarıyla train/val/test olarak bölündü!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUfkB4uAO8_q",
        "outputId": "cfd96deb-f064-4d14-893e-945e478bf773"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sınıf: Mosaic\n",
            "  Toplam: 462\n",
            "  Train:  323\n",
            "  Val:    46\n",
            "  Test:   93\n",
            "\n",
            "Sınıf: RedRot\n",
            "  Toplam: 518\n",
            "  Train:  362\n",
            "  Val:    51\n",
            "  Test:   105\n",
            "\n",
            "Sınıf: Healthy\n",
            "  Toplam: 522\n",
            "  Train:  365\n",
            "  Val:    52\n",
            "  Test:   105\n",
            "\n",
            "Sınıf: Rust\n",
            "  Toplam: 514\n",
            "  Train:  359\n",
            "  Val:    51\n",
            "  Test:   104\n",
            "\n",
            "Sınıf: Yellow\n",
            "  Toplam: 505\n",
            "  Train:  353\n",
            "  Val:    50\n",
            "  Test:   102\n",
            "\n",
            "✅ Veri başarıyla train/val/test olarak bölündü!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_images(folder):\n",
        "    total = 0\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        for f in files:\n",
        "            if f.lower().endswith(VALID_EXTENSIONS):\n",
        "                total += 1\n",
        "    return total\n",
        "\n",
        "train_count = count_images(os.path.join(SPLIT_DIR, \"train\"))\n",
        "val_count   = count_images(os.path.join(SPLIT_DIR, \"val\"))\n",
        "test_count  = count_images(os.path.join(SPLIT_DIR, \"test\"))\n",
        "\n",
        "print(\"Train toplam görüntü sayısı :\", train_count)\n",
        "print(\"Val   toplam görüntü sayısı :\", val_count)\n",
        "print(\"Test  toplam görüntü sayısı :\", test_count)\n",
        "print(\"Toplam (split) :\", train_count + val_count + test_count)\n",
        "\n",
        "raw_total = count_images(RAW_DIR)\n",
        "print(\"Ham veri toplam görüntü sayısı:\", raw_total)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RK2VQKiJPHUe",
        "outputId": "f7af39c5-d5e2-442f-b89d-1daf0ce46410"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train toplam görüntü sayısı : 1762\n",
            "Val   toplam görüntü sayısı : 250\n",
            "Test  toplam görüntü sayısı : 509\n",
            "Toplam (split) : 2521\n",
            "Ham veri toplam görüntü sayısı: 5042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tq37QD07banR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}